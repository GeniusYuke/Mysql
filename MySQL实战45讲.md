## 1 基础架构：一条SQL查询语句是如何执行的？
大体来说，MySQL可以分为Server层和存储引擎层两部分
- Server层包括连接器、查询缓存、分析器、优化器、执行器，涵盖所有的内置函数，跨存储引擎的功能（存储过程、触发器、视图）
- 存储引擎层负责数据的存储和提取，支持InnoDB、MyISAM、Memory等多个引擎
### 连接器
连接命令一般是这么写的：
```
mysql -h$ip -P$port -u$user -p
```
### 查询缓存
**查询缓存往往弊大于利**
只要有对一个表的更新，表上的所有查询缓存都会清空。一般只有在静态表上适合使用缓存（比如系统配置表，长时间更新一次）。
### 分析器
先做“词法分析”；然后做“语法分析”；
### 优化器
在表里面有多个索引的时候，决定使用哪个索引；在有多表关联（join）的时候决定各个表的连接顺序。
```
select * from t1 join t2 using(ID) where t1.c=10 and t2.d =20;
```
既可以先从表一取出c=10的记录的ID值，再根据ID值关联到表二，再判断表二里面的d的值是否等于20；也可以。。。。
### 执行器
首先判断有没有权限，然后更具表的引擎去调用接口，查询表，返回结果集
### 课后题
如果表 T 中没有字段 k，而你执行了这个语句 select * from T where k=1, 那肯定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？
**答：**分析器。Oracle会在分析阶段判断语句是否正确，表是否存在，列是否存在等。猜测MySQL也这样
## 2 日志系统：一条SQL更新语句是如何执行的？
### 重要的日志模块：redo log
**Write-Ahead Logging** 先写日志，再写磁盘。当有一条记录需要更新的时候，先会把记录写到redo log里面，更新内存，在空闲的时候把操作记录更新到磁盘里面。
即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。
### 重要的日志模块：binlog
redo log 是InnoDB引擎特有的日志，Server层的日志为binlog（归档日志）。
两种日志有以下三点不同：
1. redo log 是 InnoDB 引擎特有的；binlog是 MySQL 的 Server 层实现的，所有引擎都可以使用。
2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
### 两阶段提交
将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是"两阶段提交"。保证两份日志之间的逻辑一致。
### 课后题 
一天一备和一周一备的区别？
**答：**一天一备恢复时间更快，成本高，消耗更多存储空间
## 3 事务隔离：为什么你改变了我还看不见？
### 隔离性与隔离级别
- 读未提交：一个事务还没提交时，他做的变更就能被别的事务看到。
- 读提交：一个事务提交之后，他做的变更才能被别的事务看到。
- 可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。
- 串行化：对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。出现读写锁冲突时，后续访问事务必须等前一个事务执行完成才能继续执行。
在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。
假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。
这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。
### 事务隔离的实现
在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制（MVCC）。
**尽量不要使用长事务。**
长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。
### 事务的启动方式
1. 显式启动事务语句， begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback。
2. set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行commit 或 rollback 语句，或者断开连接。
建议使用方法一，如果考虑多一次交互问题，可以使用commit work and chain语法
### 课后题
你现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？
**答：**首先，从应用开发端来看：
确认是否使用了set autocommit=0。这个确认工作可以在测试环境中开展，把MySQL的general_log开起来，然后随便跑一个业务逻辑，通过general_log的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成1。
确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用begin/commit框起来。我见过有些是业务并没有这个需要，但是也把好几个select语句放到了事务中。这种只读事务可以去掉。
业务连接数据库的时候，根据业务本身的预估，通过SET MAX_EXECUTION_TIME命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）
其次，从数据库端来看：
监控 information_schema.Innodb_trx表，设置长事务阈值，超过就报警/或者kill；
Percona的pt-kill这个工具不错，推荐使用；
在业务功能测试阶段要求输出所有的general_log，分析日志行为提前发现问题；
如果使用的是MySQL 5.6或者更新版本，把innodb_undo_tablespaces设置成2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。
## 4 深入浅出索引（上）
索引的出现是为了提高查询效率，实现索引的方式有很多种，介绍三种常见、比较简单的数据结构：哈希表、有序数组和搜索树。
### 哈希表
哈希表是一种以键-值（key-value）存储数据的结构，输入待查找的值即key，对应的值即Value。
多个key值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。
哈希表优点**更新快，但是数据无序，查找速度慢。适用于只有等值查询的场景**
### 有序数组
**有序数组在等值查询和范围查询场景中的性能就都非常优秀。但是更新数据麻烦，只适用于静态存储引擎**
### 二叉树
搜索和更新的时间复杂度均为O(log(N))。
索引不止存在内存中，还要写到磁盘上。一棵100万节点的平衡二叉树，树高20。一次查询可能需要访问20个数据块。读一个数据块需要10 ms左右的寻址时间，单独访问一个行可能需要20个10 ms的时间。那么，我们就不应该使用二叉树，而是要使用“N叉”树。
树根的数据块总是在内存中的，第二层也有很大概率在内存中
### InnoDB 的索引模型
B+树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。
假设，我们有一个主键列为ID的表，表中有字段k，并且在k上有索引。
主键索引的叶子节点存的是整行数据。非主键索引的叶子节点内容是主键的值。
- 如果语句是select * from T where ID=500，即主键查询方式，则只需要搜索ID这棵B+树；
- 如果语句是select * from T where k=5，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为回表。
因此，我们在应用中应该尽量使用主键查询。
### 索引维护
一个数据页满了，按照B+Tree算法，新增加一个数据页，叫做页分裂，会导致性能下降。空间利用率降低大概50%。当相邻的两个数据页利用率很低的时候会做数据页合并，合并的过程是分裂过程的逆过程。
从性能和存储空间方面考量，自增主键往往是更合理的选择。
### 课后题
如果你要重建索引 k，你的两个SQL语句可以这么写：
```
alter table T drop index k;
alter table T add index(k);
```
如果你要重建主键索引，也可以这么写：
```
alter table T drop primary key;
alter table T add primary key(id);
```
对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？
**答：**索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑。
不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。可以用 alter table T engine=InnoDB代替。
## 5 深入浅出索引（下）
执行 select * from T where k between 3 and 5，需要执行5次树的搜索操作，会扫描2行。
1. 在k索引树上找到k=3的记录，取得 ID = 300；
2. 再到ID索引树查到ID=300对应的R3；
3. 在k索引树取下一个值k=5，取得ID=500；
4. 再回到ID索引树查到ID=500对应的R4；
5. 在k索引树取下一个值k=6，不满足条件，循环结束。
### 覆盖索引
如果执行的语句是select ID from T where k between 3 and 5，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。
### 最左前缀原则
B+树可以利用索引的“最左前缀”，来定位记录。
因为可以支持最左前缀，当已经有了(a,b)这个联合索引后，一般就不需要单独在a上建立索引了。
那么，如果既有联合查询，又有基于a、b各自的查询呢？查询条件里面只有b的语句，是无法使用(a,b)这个联合索引的。
### 课后题
```
CREATE TABLE `geek` (
  `a` int(11) NOT NULL,
  `b` int(11) NOT NULL,
  `c` int(11) NOT NULL,
  `d` int(11) NOT NULL,
  PRIMARY KEY (`a`,`b`),
  KEY `c` (`c`),
  KEY `ca` (`c`,`a`),
  KEY `cb` (`c`,`b`)
) ENGINE=InnoDB;
select * from geek where c=N order by a limit 1;
select * from geek where c=N order by b limit 1;
```
为了这两个查询模式，这两个索引是否都是必须的？为什么呢？
**答：**ca可以去掉，cb需要保留
## 6 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？
### 全局锁
局锁就是对整个数据库实例加锁。MySQL提供的命令是 Flush tables with read lock (FTWRL)。全局锁的典型使用场景是，做全库逻辑备份。
- 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
- 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的binlog，会导致主从延迟。
当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。
业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）
### 表级锁
MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。表锁的语法是 lock tables … read/write。MDL不需要显式使用，在访问一个表的时候会被自动加上。
当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。
- 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
- 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。
### 课后题
当备库用–single-transaction做逻辑备份的时候，如果从主库的binlog传来一个DDL语句会怎么样？
**答：**
## 7 行锁功过：怎么减少行锁对性能的影响？
在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是**两阶段锁协议**。如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。
当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为**死锁**。
- 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置。
- 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。
- ### 课后题
如果你要删除一个表里面的前10000行数据，有以下三种方法可以做到：
- 第一种，直接执行delete from T limit 10000;
- 第二种，在一个连接中循环执行20次 delete from T limit 500;
- 第三种，在20个连接中同时执行delete from T limit 500。
你会选择哪一种方法呢？为什么呢？
**答：**第二种，第一种方式单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。第三种方式会人为造成锁冲突。
## 8 事务到底是隔离的还是不隔离的？
可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。
- 对于可重复读，查询只承认在事务启动前就已经提交完成的数据；
- 对于读提交，查询只承认在语句启动前就已经提交完成的数据；
- ### 课后题
我用下面的表结构和初始化语句作为试验环境，事务隔离级别是可重复读。现在，我要把所有“字段c和id值相等的行”的c值清零，但是却发现了一个“诡异”的、改不掉的情况。请你构造出这种情况，并说明其原理。
```
mysql> CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;
insert into t(id, c) values(1,1),(2,2),(3,3),(4,4);
```
**答：** 
session A  | session B 
-|-
begin;<br>select * from t; |   
 &nbsp;| update t set c=c+1; 
update t set c=0 where id=c;<br>select * from t; |  
## 9 普通索引和唯一索引，应该怎么选择？
对于**查询过程**来说：
a、普通索引，查到满足条件的第一个记录后，继续查找下一个记录，知道第一个不满足条件的记录
b、唯一索引，由于索引唯一性，查到第一个满足条件的记录后，停止检索
但是，两者的性能差距微乎其微。因为InnoDB根据数据页来读写的。
对于**更新过程**来说：
当需要更新一个数据页，如果数据页在内存中就直接更新，如果不在内存中，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存在change buffer中。下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中的与这个页有关的操作。
purge:将change buffer中的操作应用到原数据页上，得到最新结果的过程，称为purge。
访问这个数据页会触发purge，系统有后台线程定期purge，在数据库正常关闭的过程中，也会执行purge.
唯一索引的更新不能使用change buffer.
**change buffer使用场景**
在一个数据页做purge之前，change buffer记录的变更越多，收益就越大。对于**写多读少**的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。
反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer,但之后由于马上要访问这个数据页，会立即触发purge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。所以，对于这种业务模式来说，change buffer反而起到了副作用。
索引的选择和实践：
尽可能使用普通索引。
redo log主要节省的是随机写磁盘的IO消耗(转成顺序写)，而change buffer主要节省的则是随机读磁盘的IO消耗。
- ### 课后题
如果这个时候机器掉电重启，会不会导致change buffer丢失呢？
**答：** 不会丢失。虽然是只更新内存，但是在事务提交的时候，我们把change buffer的操作也记录到redo log里了。